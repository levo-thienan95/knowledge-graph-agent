
# Knowledge Graph Agent â€” Chatbot Output Structure Specification

## Overview

The chatbot in the Knowledge Graph Agent serves as a natural language interface to interact with codebases indexed from GitHub repositories. It uses a Retrieval-Augmented Generation (RAG) architecture to answer user queries with context-aware, precise, and structured responses.

This document outlines:

- The output response structure
- Response types and formats
- JSON schema for programmatic consumption
- Sample outputs
- Diagram of the architecture and flow

---

## 1. Output Response Structure

### 1.1 Primary Elements

Each chatbot response contains:

| Field               | Type        | Description |
|---------------------|-------------|-------------|
| `answer`            | `string`    | Main answer to the user's question, generated by the LLM |
| `context_snippets`  | `array`     | Relevant code/doc/document snippets retrieved via vector search |
| `source_files`      | `array`     | Files or URLs where the information was extracted |
| `citations`         | `array`     | Inline references to source files/snippets |
| `confidence_score`  | `float`     | Confidence score (0 to 1) of the generated answer |
| `follow_up_prompts` | `array`     | Suggested follow-up questions to guide the user |

---

## 2. JSON Output Schema

```json
{
  "answer": "string",
  "context_snippets": [
    {
      "content": "string",
      "file_path": "string",
      "line_range": [start_line, end_line]
    }
  ],
  "source_files": ["string"],
  "citations": [
    {
      "file_path": "string",
      "line": "integer",
      "snippet_id": "string"
    }
  ],
  "confidence_score": 0.92,
  "follow_up_prompts": [
    "string"
  ]
}
```

---

## 3. Response Types

### 3.1 Direct Answer
- Natural language response with minimal structure
- Best for conceptual questions

### 3.2 Code Explanation
- Includes annotated code snippets
- Explains what a function or module does

### 3.3 Dependency Mapping
- Shows relationships between files, modules, or services

### 3.4 Configuration Guidance
- Explains config parameters and their effects

### 3.5 Error Diagnosis
- Responds to "Why am I seeing this error?" with traceback context and fix suggestions

---

## 4. Sample Output

```json
{
  "answer": "The function `getUserToken` retrieves the current session token from localStorage and attaches it to the Authorization header for API calls.",
  "context_snippets": [
    {
      "content": "function getUserToken() {\n  return localStorage.getItem('session_token');\n}",
      "file_path": "src/utils/auth.js",
      "line_range": [12, 14]
    }
  ],
  "source_files": ["src/utils/auth.js"],
  "citations": [
    {
      "file_path": "src/utils/auth.js",
      "line": 12,
      "snippet_id": "ctx1"
    }
  ],
  "confidence_score": 0.95,
  "follow_up_prompts": [
    "Where is the token used in API calls?",
    "Is this function secure for production?"
  ]
}
```

---

## 5. Output Architecture Diagram â€” Detailed Flow

Below is a detailed flow of how the Knowledge Graph Agent processes a user's question and generates a structured output:

```plaintext
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  User Question (NL)â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Chatbot Frontend Interface â”‚
 â”‚ (Web UI / API / Slack etc)â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚   RAG Orchestrator       â”‚
 â”‚ (Input Normalizer +      â”‚
 â”‚  Retriever + Generator)  â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Retriever Module         â”‚
 â”‚ - Embed question         â”‚
 â”‚ - Vector similarity      â”‚
 â”‚ - Retrieve top-K docs    â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Vector Store (e.g. FAISS)    â”‚
 â”‚ - Stores embeddings of code, â”‚
 â”‚   docs, configs, etc.        â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ Retrieved Context
          â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Generator (LLM, e.g. GPT-4)  â”‚
 â”‚ - Receives context + query   â”‚
 â”‚ - Generates natural response â”‚
 â”‚ - Adds citations, confidence â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Output Post-Processor              â”‚
 â”‚ - Format to JSON                   â”‚
 â”‚ - Extract follow-up prompts        â”‚
 â”‚ - Annotate sources/snippets       â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Structured Output to User          â”‚
 â”‚ - Natural answer (`string`)        â”‚
 â”‚ - Context snippets (`array`)       â”‚
 â”‚ - File sources & citations         â”‚
 â”‚ - Confidence score                 â”‚
 â”‚ - Follow-up prompts (`array`)      â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ’¡ Notes:
- Each response is grounded in real context retrieved from the vector database.
- Citations point to exact lines in GitHub files to ensure traceability.
- The full response can be consumed as a rich JSON for API or shown in Markdown in a UI.

---

## 6. Best Practices for Output

- Always provide **source attribution**
- Keep responses **grounded in retrieved context**
- Include **follow-up prompts** for deeper navigation
- Return **structured JSON** if queried via API
- Use **confidence scores** to rank ambiguous responses

---

## 7. Optional Enhancements

- Provide syntax-highlighted code blocks
- Render Markdown preview in UI
- Include a "Show full source file" link
- Add time-based caching for frequently asked questions

---
