
# Knowledge Graph Agent — Chatbot Output Structure Specification

## Overview

The chatbot in the Knowledge Graph Agent serves as a natural language interface to interact with codebases indexed from GitHub repositories. It uses a Retrieval-Augmented Generation (RAG) architecture to answer user queries with context-aware, precise, and structured responses.

This document outlines:

- The output response structure
- Response types and formats
- JSON schema for programmatic consumption
- Sample outputs
- Diagram of the architecture and flow

---

## 1. Output Response Structure

### 1.1 Primary Elements

Each chatbot response contains:

| Field               | Type        | Description |
|---------------------|-------------|-------------|
| `answer`            | `string`    | Main answer to the user's question, generated by the LLM |
| `context_snippets`  | `array`     | Relevant code/doc/document snippets retrieved via vector search |
| `source_files`      | `array`     | Files or URLs where the information was extracted |
| `citations`         | `array`     | Inline references to source files/snippets |
| `confidence_score`  | `float`     | Confidence score (0 to 1) of the generated answer |
| `follow_up_prompts` | `array`     | Suggested follow-up questions to guide the user |

---

## 2. JSON Output Schema

```json
{
  "answer": "string",
  "context_snippets": [
    {
      "content": "string",
      "file_path": "string",
      "line_range": [start_line, end_line]
    }
  ],
  "source_files": ["string"],
  "citations": [
    {
      "file_path": "string",
      "line": "integer",
      "snippet_id": "string"
    }
  ],
  "confidence_score": 0.92,
  "follow_up_prompts": [
    "string"
  ]
}
```

---

## 3. Response Types

### 3.1 Direct Answer
- Natural language response with minimal structure
- Best for conceptual questions

### 3.2 Code Explanation
- Includes annotated code snippets
- Explains what a function or module does

### 3.3 Dependency Mapping
- Shows relationships between files, modules, or services

### 3.4 Configuration Guidance
- Explains config parameters and their effects

### 3.5 Error Diagnosis
- Responds to "Why am I seeing this error?" with traceback context and fix suggestions

---

## 4. Sample Output

```json
{
  "answer": "The function `getUserToken` retrieves the current session token from localStorage and attaches it to the Authorization header for API calls.",
  "context_snippets": [
    {
      "content": "function getUserToken() {\n  return localStorage.getItem('session_token');\n}",
      "file_path": "src/utils/auth.js",
      "line_range": [12, 14]
    }
  ],
  "source_files": ["src/utils/auth.js"],
  "citations": [
    {
      "file_path": "src/utils/auth.js",
      "line": 12,
      "snippet_id": "ctx1"
    }
  ],
  "confidence_score": 0.95,
  "follow_up_prompts": [
    "Where is the token used in API calls?",
    "Is this function secure for production?"
  ]
}
```

---

## 5. Output Architecture Diagram — Detailed Flow

Below is a detailed flow of how the Knowledge Graph Agent processes a user's question and generates a structured output:

```plaintext
 ┌────────────────────┐
 │  User Question (NL)│
 └────────┬───────────┘
          │
          ▼
 ┌────────────────────────────┐
 │ Chatbot Frontend Interface │
 │ (Web UI / API / Slack etc)│
 └────────┬───────────────────┘
          │
          ▼
 ┌──────────────────────────┐
 │   RAG Orchestrator       │
 │ (Input Normalizer +      │
 │  Retriever + Generator)  │
 └────────┬─────────────────┘
          │
          ▼
 ┌──────────────────────────┐
 │ Retriever Module         │
 │ - Embed question         │
 │ - Vector similarity      │
 │ - Retrieve top-K docs    │
 └────────┬─────────────────┘
          │
          ▼
 ┌──────────────────────────────┐
 │ Vector Store (e.g. FAISS)    │
 │ - Stores embeddings of code, │
 │   docs, configs, etc.        │
 └────────┬─────────────────────┘
          │ Retrieved Context
          ▼
 ┌──────────────────────────────┐
 │ Generator (LLM, e.g. GPT-4)  │
 │ - Receives context + query   │
 │ - Generates natural response │
 │ - Adds citations, confidence │
 └────────┬─────────────────────┘
          │
          ▼
 ┌────────────────────────────────────┐
 │ Output Post-Processor              │
 │ - Format to JSON                   │
 │ - Extract follow-up prompts        │
 │ - Annotate sources/snippets       │
 └────────┬───────────────────────────┘
          │
          ▼
 ┌────────────────────────────────────┐
 │ Structured Output to User          │
 │ - Natural answer (`string`)        │
 │ - Context snippets (`array`)       │
 │ - File sources & citations         │
 │ - Confidence score                 │
 │ - Follow-up prompts (`array`)      │
 └────────────────────────────────────┘
```

### 💡 Notes:
- Each response is grounded in real context retrieved from the vector database.
- Citations point to exact lines in GitHub files to ensure traceability.
- The full response can be consumed as a rich JSON for API or shown in Markdown in a UI.

---

## 6. Best Practices for Output

- Always provide **source attribution**
- Keep responses **grounded in retrieved context**
- Include **follow-up prompts** for deeper navigation
- Return **structured JSON** if queried via API
- Use **confidence scores** to rank ambiguous responses

---

## 7. Optional Enhancements

- Provide syntax-highlighted code blocks
- Render Markdown preview in UI
- Include a "Show full source file" link
- Add time-based caching for frequently asked questions

---
